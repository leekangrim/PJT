# 인공지능 정리



![](https://blogfiles.pstatic.net/MjAyMDA0MDNfMTA2/MDAxNTg1OTExMDQ1NTI5.P17sN8p2a9-VLxBj925pnc5VObM_bjGZXMF9b_dW_zcg.B3qmjqddpLwMzuH02GGhkM79Nxut3pmCGhVe-PGx6dIg.PNG.kjh920411/image.png)

- 인공지능 
  - 인간이 수행하는 **지능적인 작업을 자동화**하기 위한 연구 활동
- 머신러닝
  - 인공지능의 하위 개념으로, 주어진 정확한 결정을 내리기 위해 제공된 **데이터를 통하여 스스로 학습**하는 것
- 딥러닝
  - 머신러닝을 구현하는 기술 중 하나인 **인공신경망에서 발전한 형태의 인공 지능**으로, **뇌의 뉴런과 유사한 정보 입출력 계층(퍼셉트론)을 활용해 데이터를 학습**



- 머신러닝과 딥러닝의 차이
  - **머신러닝은 사람이 직접 중요한 feature( 머신러닝, 딥러닝 에서 입력으로 주어지는 변수들을 주로 feature라고 부름)를 제공해주는 수동적인 학습**을 진행하는 반면, **딥러닝은 분류에 있어 중요한 feature를 자동적으로 골라내는 작업**



# 머신러닝 정리



- 머신러닝을 사용하는 이유
  - 머신 러닝은 주어진 데이터로부터 결과를 찾는 것에 초점을 맞추는 것이 아니라, **주어진 데이터로부터 규칙성을 찾는 것에 초점**이 맞추어져 있습니다. **주어진 데이터로부터 규칙성을 찾는 과정을 우리는 학습(training)**이라고 합니다
  - 일단 규칙성을 발견해내면, 그 후에 들어오는 **새로운 데이터에 대해서 발견한 규칙성을 기준으로 정답을 찾아**내는데, 이는 **기존의 프로그래밍 방식으로 접근하기 어려웠던 문제의 해결책**이 되기도 합니다.



- 평가

  - 실제 모델을 평가하기 위해서 데이터를 훈련용, 검증용, 테스트용 이렇게 세 가지로 분리

- 검증용 데이터

  - 검증용 데이터는 모델의 성능을 평가하기 위한 용도가 아니라, 모델의 성능을 조정하기 위한 용도

  - 더 정확히는 과적합이 되고 있는지 판단하거나 하이퍼파라미터의 조정을 위한 용도

  - 훈련용 데이터로 훈련을 모두 시킨 모델은 검증용 데이터를 사용하여 정확도를 검증하며 하이퍼파라미터를 **튜닝(tuning)**
    이 모델의 매개변수는 검증용 데이터로 정확도가 검증되는 과정에서 점차 검증용 데이터에 점점 맞추어져 가기 시작

  - 하이퍼파라미터 튜닝이 끝났다면, 이제 검증용 데이터로 모델을 평가하는 것은 적합하지 않습니다.
    모델은 검증용 데이터에 대해서도 일정 부분 최적화가 되어있기 때문

  - 모델에 대한 평가는 모델이 아직까지 보지 못한 데이터로 하는 것이 가장 바람직

    검증이 끝났다면 테스트 데이터를 가지고 모델의 진짜 성능을 평가

- 하이퍼파라미터(초매개변수)

  - 모델의 성능에 영향을 주는 매개변수
  - 사람이 정하는 변수
  - 학습률(learning rate), 은닉층 수, 뉴런 수, 드롭아웃 비율, ...

- 매개변수

  - 학습을 통해 바뀌어져가는 변수
  - 기계가 훈련을 통해서 바꾸는 변수
  - 가중치, 편향, ...



- 회귀 문제
- 선형 회귀
- 이진 분류
- 다중 클래스 분류



- 지도 학습

  - **레이블(Label)이라는 정답과 함께 학습**하는 것을 말합니다. 레이블이라는 말 외에도 y, 실제값 등으로 부르기도 함

    이때 **기계는 예측값과 실제값의 차이인 오차를 줄이는 방식으로 학습**을 하게 되는데 예측값은 y^과 같이 표현하기도 함

- 비지도 학습
  - **레이블이 없이 학습**



- 혼동 행렬
- 정밀도(Precision)

  - 양성이라고 대답한 전체 케이스에 대한 TP의 비율
  - 정밀도=TP/(TP+FP)
- 재현율(Recall)
  - 실제값이 양성인 데이터의 전체 개수에 대해서 TP의 비율
    즉, 양성인 데이터 중에서 얼마나 양성인지를 예측(재현)했는지
  - 재현율=TP/(TP+FN)



- 과적합
  - 훈련 데이터를 과하게 학습한 경우
  - 훈련 데이터에 대해서는 오차가 낮지만, 테스트 데이터에 대해서는 오차가 높아지는 상황이 발생
- 과소적합
  -  훈련 자체가 부족한 상태
  - 테스트 데이터의 성능이 올라갈 여지가 있음에도 훈련을 덜 한 상태
  - 훈련 데이터에 대해서도 보통 정확도가 낮다



- 과적합을 맊는 방법
  - 데이터 양 늘리기
  - 모델 복작도 줄이기
  - 가중치 규제 적용
  - 드롭아웃
  - 앙상블
  - 조기 종료



# 딥러닝 정리



- 퍼셉트론
  - 다수의 입력으로부터 하나의 결과를 내보내는 알고리즘
    - 각 입력값이 가중치와 곱해져서 인공 뉴런에 보내지고, 각 입력값과 그에 해당되는 가중치의 곱의 전체 합이 임계치(threshold)를 넘으면 종착지에 있는 인공 뉴런은 출력 신호로서 1을 출력하고, 그렇지 않을 경우에는 0을 출력. 이러한 함수를 계단 함수(Step function)
    - 각각의 입력값에는 각각의 가중치가 존재하는데, 이때 가중치의 값이 크면 클수록 해당 입력 값이 중요하다는 것을 의미
    - 임계치를 좌변으로 넘기고 편향 b(bias)로 표현할 수도 있음. (편향 b 또한 퍼셉트론의 입력으로 사용)
  - 뉴런에서 출력값을 변경시키는 함수를 활성화 함수(Activation Function)

- 단층 퍼셉트론
  - 입력층과 출력층만 존재
  - 선형 영역에 대해서만 분리가 가능
- 다층 퍼셉트론
  - 입력층과 출력층 사이에 중간에 층을 더 추가하여 **은닉층(hidden layer)** 존재
  - 비선형 영역에 대해서만 분리가 가능



- 단층 퍼셉트론과 다층 퍼셉트론의 차이
  - 단층 퍼셉트론은 AND 게이트, NAND 게이트, OR 게이트 또한 구현 가능
  - **단층 퍼셉트론으로  XOR 게이트 구현 불가능**
  - XOR 게이트는 기존의 AND, NAND, OR 게이트를 조합하면 만들 수 있습니다. 
  - 퍼셉트론 관점에서 말하면, 층을 더 쌓으면 만들 수 있습니다.
  -  즉, AND, NAND, OR 게이트를 구현한 퍼셉트론을 조합하여, 2개의 층으로 이루어진 다층 퍼셉트론으로 XOR 게이트 구현 가능



- 인공신경망 

  - 피드 포워드 신경망(Feed-Forward Neural Network, FFNN)
    - 입력층에서 출력층 방향으로 연산이 전개되는 신경망
  - RNN
    - 은닉층의 출력값을 출력층으로도 값을 보내지만, 동시에 은닉층의 출력값이 다시 은닉층의 입력, FFNN의 정의에 벗어납
  - 전결합층(Fully-connected layer, FC, Dense layer)
    - 어떤 층의 모든 뉴런이 이전 층의 모든 뉴런과 연결돼 있는 층을 전결합층
  - 활성화 함수
    - 은닉층과 출력층의 뉴런에서 출력값을 결정하는 함수
    - 비선형함수
      - **선형 함수로는 은닉층을 여러번 추가하더라도 1회 추가한 것과 차이를 줄 수 없습니다.**
    - 예시
      - 계단 함수
      - 시그모이드 함수
        - 기울기 소실 문제
      - 하이퍼블릭 탄젠트 함수 (hyperbolic tangent function)
      - 렐루 함수 (ReLU)
        - 기울기 소실 문제 해결
        - 죽은 렐루(dying ReLU)
      - **리키 렐루 (Leaky ReLU)**
        - 죽은 렐루(dying ReLU) 보완
      - 소프트맥스 함수
        - 다중 클래스 분류



- 딥러닝 학습 방법
  - 순전파(Forward Propagation)
    - 입력값은 입력층, 은닉층을 지나면서 각 층에서의 가중치와 함께 연산되며 출력층으로 향합니다. 그리고 출력층에서 모든 연산을 마친 예측값이 나오게 됩니다. 
    - 이와 같이 입력층에서 출력층 방향으로 예측값의 연산이 진행되는 과정을 순전파
  - 손실 함수(Loss Function)
    - 손실 함수는 실제값과 예측값의 차이를 수치화해주는 함수
    - 손실 함수의 값을 최소화하는 두 개의 매개변수인 가중치 W와 편향 b를 찾아가는 것이 딥러닝의 학습 과정
    - 예시
      - 오차 제곱 평균 (Mean Squared Error, MSE)
      - 크로스 엔트로피 (Cross-Entropy)
  - 옵티마이저
    - 손실 함수의 값을 줄여나가면서 학습하는 방법은 어떤 옵티마이저를 사용하느냐에 따라 달라집
    - 예시
      - 배치 경사 하강법(Batch Gradient Descent)
      - 확률적 경사 하강법(SGD)
      - 미니 배치 경사 하강법(Mini - Batch Gradient Descent)
      - 모멘텀(Momentum)
      - 아다그라드(Adagrad)
      - 알 엠 에스 프롭 (RMSprop)
      - 아담(Adam)
  - 에포크 (Epochs) ? 배치 크기 (Batch size) ? 이터레이션(Iteration)

    - 기계는 실제값과 예측값의 오차로부터 옵티마이저를 통해서 가중치를 업데이트합니다. 머신 러닝에서는 이 과정을 **학습**이라고 합니다. 
  - 에포크

    - 에포크란 인공 신경망에서 전체 데이터에 대해서 순전파와 역전파가 끝난 상태
  - 배치 사이즈

    - 배치 크기는 몇 개의 데이터 단위로 매개변수를 업데이트 하는지

  - 이터레이션

    - 이터레이션이란 한 번의 에포크를 끝내기 위해서 필요한 배치의 수



- 역전파
  - 순전파가 입력층에서 출력층으로 향한다면 역전파는 반대로 출력층에서 입력층 방향으로 계산하면서 가중치를 업데이트
  - 출력층 바로 이전의 은닉층을 N층이라고 하였을 때, 출력층과 N층 사이의 가중치를 업데이트하는 단계를 역전파 1단계, 그리고 N층과 N층의 이전층 사이의 가중치를 업데이트 하는 단계를 역전파 2단계



- 기울기 소실
  - 깊은 인공 신경망을 학습하다보면 역전파 과정에서 입력층으로 갈 수록 기울기(Gradient)가 점차적으로 작아지는 현상이 발생할 수 있습니다. 입력층에 가까운 층들에서 가중치들이 업데이트가 제대로 되지 않으면 결국 최적의 모델을 찾을 수 없게 됩니다. 이를 **기울기 소실(Gradient Vanishing)**
- 폭주
  - 점차 커지더니 가중치들이 비정상적으로 큰 값이 되면서 결국 발산되기도 합니다. 이를 **기울기 폭주(Gradient Exploding)**이라고 하며, 뒤에서 배울 순환 신경망(Recurrent Neural Network, RNN)에서 발생할 수 있습니다.



- 기울기 소실 방지법
  - ReLU와 ReLU 변형
  - 그래디언트 클리핑 (Gradient Clipping)
    - 그래디언트 클리핑은 말 그대로 기울기 값을 자르는 것을 의미합니다. 기울기 폭주를 막기 위해 임계값을 넘지 않도록 값을 자릅니다. 다시 말해서 임계치만큼 크기를 감소시킵니다. 이는 RNN에서 유용합니다. RNN은 BPTT에서 시점을 역행하면서 기울기를 구하는데, 이때 기울기가 너무 커질 수 있기 때문입니다. 케라스에서는 다음과 같은 방법으로 그래디언트 클리핑을 수행
  - 가중치 초기화
    - 같은 모델을 훈련시키더라도 가중치가 초기에 어떤 값을 가졌느냐에 따라서 모델의 훈련 결과가 달라지기도 합니다. 다시 말해 가중치 초기화만 적절히 해줘도 기울기 소실 문제과 같은 문제를 완화
      - 세이비어 초기화(Xavier Initialization)
      - He 초기화
  - 배치 정규화
    - 배치 정규화는 인공 신경망의 각 층에 들어가는 입력을 평균과 분산으로 정규화하여 학습을 효율적으로 만듭니다
      - 내부 공변량 변화(internal Covariate Shift)
      - 배치 정규화(batch Normalization)
  - 층 정규화

