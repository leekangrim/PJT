# 인공지능 질문



## 인공지능 기본지식

![](%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%20%EC%A7%88%EB%AC%B8.assets/image.png)

- 인공지능이란? 머신러닝이란? 딥러닝이란?

  - 인공지능

    - 사람이 수행하는 지능적인 작업을 자동화하기 위한 연구 활동

  - 머신러닝

    - 인공지능의 하위 집한 개념으로 주어진 **정확한 결정을 내리기 위해 제공된 데이터를 통하여 스스로 학습**하는 것

    - 처리될 정보에 대해 더 많이 배울 수 있도록 많은 양의 데이터를 제공해야 합니다. 즉, 빅데이터를 통한 학습 방법으로 머신러닝을 이용할 수 있습니다. 

      머신 러닝은 **기본적으로 알고리즘을 이용해 데이터를 분석하고, 분석을 통해 학습하며, 학습한 내용을 기반으로 판단이나 예측**을 합니다. 
      따라서 **궁극적으로는 의사 결정 기준에 대한 구체적인 지침을 소프트웨어에 직접 코딩해 넣는 것이 아닌, 대량의 데이터와 알고리즘을 통해 컴퓨터 그 자체를 ‘학습’시켜 작업 수행 방법을 익히는 것을 목표**로 한답니다.
    
  - 딥러닝

    - 머신러닝을 구현하는 기술 중 하나인 **인공신경망에서 발전한 형태의 인공 지능**으로, **뇌의 뉴런과 유사한 정보 입출력 계층을 활용해 데이터를 학습**



- 머신러닝과 딥러닝의 차이는?

  - **머신러닝은 사람이 직접 중요한 feature( 머신러닝, 딥러닝 에서 입력으로 주어지는 변수들을 주로 feature라고 부름)를 제공해주는 수동적인 학습**을 진행하는 반면, **딥러닝은 분류에 있어 중요한 feature를 자동적으로 골라내는 작업**
    
     따라서 **딥러닝의 경우 데이터의 양이 충분하지 않다면 성능에 한계**가 있습니다. 반면 **충분한 데이터가 주어진다면 사람이 인지하지 못한 더 주요한 feature를 찾아낼 수 있으며, 종종 더 좋은 성능을 내곤 합니다.** 



## 머신러닝



- 머신러닝을 사용하는 이유는?

  - 머신 러닝은 주어진 데이터로부터 결과를 찾는 것에 초점을 맞추는 것이 아니라, 주어진 데이터로부터 규칙성을 찾는 것에 초점이 맞추어져 있습니다. 주어진 데이터로부터 규칙성을 찾는 과정을 우리는 학습(training)이라고 합니다.

    일단 규칙성을 발견해내면, 그 후에 들어오는 새로운 데이터에 대해서 발견한 규칙성을 기준으로 정답을 찾아내는데, 이는 기존의 프로그래밍 방식으로 접근하기 어려웠던 문제의 해결책이 되기도 합니다.



- 머신러닝의 평가

  - 실제 모델을 평가하기 위해서 데이터를 훈련용, 검증용, 테스트용 이렇게 세 가지로 분리

  - 검증용 데이터

    - 검증용 데이터는 모델의 성능을 평가하기 위한 용도가 아니라, **모델의 성능을 조정**하기 위한 용도
    - 더 정확히는 과적합이 되고 있는지 판단하거나 **하이퍼파라미터의 조정**을 위한 용도
      - **하이퍼파라미터(초매개변수)**란 값에 따라서 모델의 성능에 영향을 주는 매개변수들을 말합니다. 
        반면, 가중치와 편향과 같은 학습을 통해 바뀌어져가는 변수를 이 책에서는 **매개변수**라고 부릅니다.
    
      - 이 두 값 **하이퍼파라미터**와 **매개변수**의 가장 큰 **차이는 하이퍼파라미터는 보통 사용자가 직접 정해줄 수 있는 변수**라는 점입니다. 뒤의 선형 회귀 챕터에서 배우게 되는 경사 하강법에서 **학습률**(learning rate)이 이에 해당되며 **딥 러닝에서는 은닉층의 수, 뉴런의 수, 드롭아웃 비율 등**이 이에 해당됩니다. 
        반면 여기서 언급하는 **매개변수는 사용자가 결정해주는 값이 아니라 모델이 학습하는 과정에서 얻어지는 값**입니다. 
    
        정리하면 절대적인 정의라고는 할 수 없지만, 하이퍼파라미터는 사람이 정하는 변수인 반면, 매개변수는 기계가 훈련을 통해서 바꾸는 변수라고 할 수 있으며 이 책에서는 이와 같은 기준으로 변수의 이름을 명명합니다.
    - 훈련용 데이터로 훈련을 모두 시킨 모델은 검증용 데이터를 사용하여 정확도를 검증하며 하이퍼파라미터를 **튜닝(tuning)**합니다. 또한 이 모델의 매개변수는 검증용 데이터로 정확도가 검증되는 과정에서 점차 검증용 데이터에 점점 맞추어져 가기 시작
    
    - 하이퍼파라미터 튜닝이 끝났다면, 이제 검증용 데이터로 모델을 평가하는 것은 적합하지 않습니다. 이제 모델은 검증용 데이터에 대해서도 일정 부분 최적화가 되어있기 때문입니다. 모델에 대한 평가는 모델이 아직까지 보지 못한 데이터로 하는 것이 가장 바람직합니다. 검증이 끝났다면 테스트 데이터를 가지고 모델의 진짜 성능을 평가



- 분류 ? 회귀 ?

  - 분류는 또한 이진 분류(Binary Classification)과 다중 클래스 분류(Multi-Class Classification)로 나뉩니다.
  - 이진 분류 문제(Binary Classification)
    - 이진 분류는 주어진 입력에 대해서 둘 중 하나의 답을 정하는 문제입니다. 시험 성적에 대해서 합격, 불합격인지 판단하고 메일로부터 정상 메일, 스팸 메일인지를 판단하는 문제 등이 이에 속합니다.
  - 다중 클래스 분류
    - 다중 클래스 분류는 주어진 입력에 대해서 두 개 이상의 정해진 선택지 중에서 답을 정하는 문제입니다. 예를 들어 서점 아르바이트를 하는데 과학, 영어, IT, 학습지, 만화라는 레이블이 각각 붙여져 있는 5개의 책장이 있다고 합시다. 새 책이 입고되면, 이 책은 다섯 개의 책장 중에서 분야에 맞는 적절한 책장에 책을 넣어야 합니다. 이 때의 다섯 개의 선택지를 주로 카테고리 또는 범주 또는 클래스라고 하며, 주어진 입력으로부터 정해진 클래스 중 하나로 판단하는 것을 다중 클래스 분류 문제라고 합니다.
  - 회귀 문제
    - 회귀 문제는 분류 문제처럼 0 또는 1이나 과학 책장, IT 책장 등과 같이 분리된(비연속적인) 답이 결과가 아니라 연속된 값을 결과로 가집니다. 예를 들어 시험 성적을 예측하는데 5시간 공부하였을 때 80점, 5시간 1분 공부하였을 때는 80.5점, 7시간 공부하였을 때는 90점 등이 나오는 것과 같은 문제가 있습니다. 그 외에도 시계열 데이터를 이용한 주가 예측, 생산량 예측, 지수 예측 등이 이에 속합니다



- 지도학습 ? 비지도학습?

  - 지도학습

    - **지도 학습이란 레이블(Label)이라는 정답과 함께 학습**하는 것을 말합니다. 레이블이라는 말 외에도 y, 실제값 등으로 부르기도 하는

      이때 기**계는 예측값과 실제값의 차이인 오차를 줄이는 방식으로 학습**을 하게 되는데 예측값은 y^과 같이 표현하기도 합니다.

  - 비지도학습

    - 반면, 비지도 학습은 **레이블이 없이 학습**하는 것을 말합니다. 예를 들어 토픽 모델링의 LDA는 비지도 학습에 속하며, 뒤에서 배우게 되는 워드투벡터(Word2Vec)는 마치 지도 학습을 닮았지만, 비지도 학습에 속합니다.



- 샘플(sample)? 특징(feature)?
  - 많은 머신 러닝 문제가 1개 이상의 독립 변수 x를 가지고 종속 변수 y를 예측하는 문제입니다. 많은 머신 러닝 모델들, 특히 인공 신경망 모델은 독립 변수, 종속 변수, 가중치, 편향 등을 행렬 연산을 통해 연산하는 경우가 많습니다. 그래서 앞으로 인공 신경망을 배우게되면 훈련 데이터를 행렬로 표현하는 경우를 많이 보게 될 겁니다. 독립 변수 x의 행렬을 X라고 하였을 때, 독립 변수의 개수가 n개이고 데이터의 개수가 m인 행렬 X
  - 이때 머신 러닝에서는 하나의 데이터, 하나의 행을 샘플(Sample)이라고 부릅니다. (데이터베이스에서는 레코드라고 부르는 단위입니다.) 종속 변수 yy를 예측하기 위한 각각의 독립 변수 xx를 특성(Feature)이라고 부릅니다.



- 혼동행렬
  - 머신 러닝에서는 맞춘 문제수를 전체 문제수로 나눈 값을 정확도(Accuracy)라고 합니다. 하지만 정확도는 맞춘 결과와 틀린 결과에 대한 세부적인 내용을 알려주지는 않습니다. 이를 위해서 사용하는 것이 혼동 행렬(Confusion Matrix)
  - 정밀도
    - 정밀도은 **양성이라고 대답한 전체 케이스에 대한 TP**의 비율입니다.
    - 정밀도=TP/(TP+FP)
  - 재현율
    - 재현율은 **실제값이 양성인 데이터의 전체 개수에 대해서 TP의 비율**입니다. 즉, 양성인 데이터 중에서 얼마나 양성인지를 예측(재현)했는지를 나타냅니다.
    - 재현율=TP/(TP+FN)



- 과적합 ? 과소적합 ?
  - 과적합
    - **과적합(Overfitting)**이란 **훈련 데이터를 과하게 학습한 경우**를 말합니다. 훈련 데이터는 실제로 존재하는 많은 데이터의 일부에 불과합니다. 그런데 **기계가 훈련 데이터에 대해서만 과하게 학습하면 테스트 데이터나 실제 서비스에서의 데이터에 대해서는 정확도가 좋지 않은 현상이 발생**합니다.
    - **과적합 상황에서는 훈련 데이터에 대해서는 오차가 낮지만, 테스트 데이터에 대해서는 오차가 높아지는 상황이 발생**
  - 과소적합
    - 과적합 방지를 위해 테스트 데이터의 성능이 낮아지기 전에 훈련을 멈추는 것이 바람직하다고 했는데, 
    
      테스트 데이터의 성능이 올라갈 여지가 있음에도 훈련을 덜 한 상태를 반대로 과소적합(Underfitting)이라고 합니다. 과소 적합은 훈련 자체가 부족한 상태이므로 과대 적합과는 달리 훈련 데이터에 대해서도 보통 정확도가 낮다는 특징이 있습니다.



- 과적합(Overfitting)을 맊는 방법 ?

  - https://bluejake.tistory.com/16

  - 데이터의 양을 늘리기

    - 모델은 데이터의 양이 적을 경우, 해당 데이터의 특정 패턴이나 노이즈까지 쉽게 암기하기 되므로 과적합 현상이 발생할 확률이 늘어납니다. 그렇기 때문에 데이터의 양을 늘릴 수록 모델은 데이터의 일반적인 패턴을 학습하여 과적합을 방지할 수 있습니다.
    - 만약, 데이터의 양이 적을 경우에는 의도적으로 기존의 데이터를 조금씩 변형하고 추가하여 데이터의 양을 늘리기도 하는데 이를 데이터 증식 또는 증강(Data Augmentation)이라고 합니다. 이미지의 경우에는 데이터 증식이 많이 사용되는데 이미지를 돌리거나 노이즈를 추가하고, 일부분을 수정하는 등으로 데이터를 증식시킵니다.

  - 모델의 복잡도 줄이기

    - 인공 신경망의 복잡도는 은닉층(hidden layer)의 수나 매개변수의 수 등으로 결정됩니다. 과적합 현상이 포착되었을 때, 인공 신경망 모델에 대해서 할 수 있는 한 가지 조치는 인공 신경망의 복잡도를 줄이는 것 입니다.

      (인공 신경망에서는 모델에 있는 매개변수들의 수를 모델의 수용력이라고 함)

  - 가중치 규제 적용

    - 복잡한 모델이 간단한 모델보다 과적합될 가능성이 높습니다. 그리고 간단한 모델은 적은 수의 매개변수를 가진 모델을 말합니다. 복잡한 모델을 좀 더 간단하게 하는 방법으로 가중치 규제(Regularizaiton)가 있습니다.
      - L1 규제 : 가중치 w들의 절대값 합계를 비용 함수에 추가합니다. L1 노름이라고도 합니다.	
      - L2 규제 : 모든 가중치 w들의 제곱합을 비용 함수에 추가합니다. L2 노름이라고도 합니다.
      - L2 규제는 L1 규제와는 달리 가중치들의 제곱을 최소화하므로 w의 값이 완전히 0이 되기보다는 0에 가까워지기는 경향을 띕니다. L1 규제는 어떤 특성들이 모델에 영향을 주고 있는지를 정확히 판단하고자 할 때 유용합니다. 만약, 이런 판단이 필요없다면 경험적으로는 L2 규제가 더 잘 동작하므로 L2 규제를 더 권장합니다. 인공 신경망에서 L2 규제는 가중치 감쇠(weight decay)라고도 부릅니다.

  - 드롭아웃

    - 드롭아웃은 학습 과정에서 신경망의 일부를 사용하지 않는 방법입니다. 예를 들어 드롭아웃의 비율을 0.5로 한다면 학습 과정마다 랜덤으로 절반의 뉴런을 사용하지 않고, 절반의 뉴런만을 사용합니다.
    - 드롭아웃은 신경망 학습 시에만 사용하고, 예측 시에는 사용하지 않는 것이 일반적입니다. 학습 시에 인공 신경망이 특정 뉴런 또는 특정 조합에 너무 의존적이게 되는 것을 방지해주고, 매번 랜덤 선택으로 뉴런들을 사용하지 않으므로 서로 다른 신경망들을 앙상블하여 사용하는 것 같은 효과를 내어 과적합을 방지합니다.

  - 앙상블

    - 앙상블 기법은 NN 모델을 여러 개로 나누어 학습한 뒤 이를 모두 합쳐서 결과를 예측한다. 단일 모델을 사용하는 것보다 2 ~ 5% 정도의 정확도가 높아진다고 한다.
  
  - 조기 종료(Early Stopping)
  
    - 이전 모델의 값을 저장해두었다가, 과적합이 발생하면 이전의 상태로 되돌리고 훈련을 멈춤
  
    
  
- 선형 회귀?



- 로지스틱 회귀?



- 소프트맥스 회귀 ? 다중 클래스 분류?



## 딥러닝



- 퍼셉트론 ?
  - 다수의 입력으로부터 하나의 결과를 내보내는 알고리즘
  - 각 입력값이 가중치와 곱해져서 인공 뉴런에 보내지고, 각 입력값과 그에 해당되는 가중치의 곱의 전체 합이 임계치(threshold)를 넘으면 종착지에 있는 인공 뉴런은 출력 신호로서 1을 출력하고, 그렇지 않을 경우에는 0을 출력합니다. 이러한 함수를 계단 함수(Step function)라고 함
  - 각각의 입력값에는 각각의 가중치가 존재하는데, 이때 가중치의 값이 크면 클수록 해당 입력 값이 중요하다는 것을 의미
  - 임계치를 좌변으로 넘기고 편향 b(bias)로 표현할 수도 있음, 편향 bb 또한 퍼셉트론의 입력으로 사용
  - 이렇게 뉴런에서 출력값을 변경시키는 함수를 활성화 함수(Activation Function)
    - 초기 인공 신경망 모델인 퍼셉트론은 활성화 함수로 계단 함수를 사용하였지만, 그 뒤에 등장한 여러가지 발전된 신경망들은 계단 함수 외에도 여러 다양한 활성화 함수를 사용하기 시작했습니다. 사실 앞서 배운 시그모이드 함수나 소프트맥스 함수 또한 활성화 함수 중 하나
- 단층 퍼셉트론
  - 값을 보내는 단계과 값을 받아서 출력하는 두 단계로만 이루어짐
  - 이 각 단계를 보통 층(layer)라고 부르며, 이 두 개의 층을 입력층(input layer)과 출력층(output layer)
  - 단층 퍼셉트론으로는 XOR 게이트를 구현하는 것이 불가능합니다. 
    - 이를 단층 퍼셉트론은 선형 영역에 대해서만 분리가 가능하다고 말합니다. 
    - 다시 말하면 XOR 게이트는 직선이 아닌 곡선. 비선형 영역으로 분리하면 구현이 가능
    - XOR 게이트는 기존의 AND, NAND, OR 게이트를 조합하면 만들 수 있습니다. 퍼셉트론 관점에서 말하면, 층을 더 쌓으면 만들 수 있습니다.
- 다층 퍼셉트론
  - 입력층과 출력층 사이에 중간에 층을 더 추가하여 **은닉층(hidden layer)** 존재
    - 은닉층이 2개 이상인 신경망을 **심층 신경망(Deep Neural Network, DNN)**
    - 기계가 가중치를 스스로 찾아내도록 자동화시켜야하는데, 이것이 머신 러닝에서 말하는 **학습(training)** 단계
    - 만약 학습을 시키는 인공 신경망이 심층 신경망일 경우에는 이를 심층 신경망을 학습시킨다고 하여, **딥 러닝(Deep Learning)**
      - **손실 함수(Loss function)**와 **옵티마이저(Optimizer)**를 사용
  - 비선형 영역에 대해서만 분리가 가능



- 인공신경망 ?

  - 피드 포워드 신경망(Feed-Forward Neural Network, FFNN)
  - 전결합층(Fully-connected layer, FC, Dense layer)
  - 활성화 함수
    - 특징 - 비선형 함수
    - **선형 함수로는 은닉층을 여러번 추가하더라도 1회 추가한 것과 차이를 줄 수 없습니다.**
    - 선형 함수를 사용한 은닉층을 1회 추가한 것과 연속으로 추가한 것이 차이가 없다는 뜻이지, 선형 함수를 사용한 층이 아무 의미가 없다는 뜻이 아닙니다. 학습 가능한 가중치가 새로 생긴다는 점에서 분명히 의미가 있습니다. 이와 같이 선형 함수를 사용한 층을 활성화 함수를 사용하는 은닉층과 구분하기 위해서 선형층(linear layer)이나 투사층(projection layer) 등의 다른 표현을 사용하여 표현하기도 합니다. 활성화 함수를 사용하는 일반적인 은닉층을 선형층과 대비되는 표현을 사용하면 비선형층(nonlinear layer)입니다.
      - 계단 함수
      - 시그모이드 함수? 기울기 소실?
        - 인공 신경망의 학습 과정은 다음과 같습니다. 우선 인공 신경망은 입력에 대해서 순전파(forward propagation) 연산을 하고, 그리고 순전파 연산을 통해 나온 예측값과 실제값의 오차를 손실 함수(loss function)을 통해 계산하고, 그리고 이 손실(loss)을 미분을 통해서 기울기(gradient)를 구하고, 이를 통해 역전파(back propagation)를 수행
        - 시그모이드 함수의 문제점은 미분을 해서 기울기(gradient)를 구할 때 발생
        - 양 끝단의 기울기를 계산하면 0에 가까운 아주 작은 값이 나오게 됩니다. 그런데 역전파 과정에서 0에 가까운 아주 작은 기울기가 곱해지게 되면, 앞단에는 기울기가 잘 전달되지 않게 됩니다. 이러한 현상을 **기울기 소실(Vanishing Gradient) 문제**
          - 출력층과 가까운 은닉층에서는 기울기가 잘 전파되지만, 앞단으로 갈수록 기울기가 제대로 전파되지 않는 모습을 보여줍니다. 결론적으로 시그모이드 함수를 은닉층에서 사용하는 것은 지양
      - 하이퍼블릭 탄젠트 함수 (hyperbolic tangent function)
      - 렐루 함수 (ReLU)
        - 렐루 함수는 특정 양수값에 수렴하지 않으므로 깊은 신경망에서 시그모이드 함수보다 훨씬 더 잘 작동합니다. 뿐만 아니라, 렐루 함수는 시그모이드 함수와 하이퍼볼릭탄젠트 함수와 같이 어떤 연산이 필요한 것이 아니라 단순 임계값이므로 연산 속도도 빠릅니다.
        - 하지만 여전히 문제점이 존재하는데, 입력값이 음수면 기울기도 0이 됩니다. 그리고 이 뉴런은 다시 회생하는 것이 매우 어렵습니다. 이 문제를 죽은 렐루(dying ReLU)라고 합니다.
      - 리키 렐루 (Leaky ReLU)
        - 죽은 렐루를 보완하기 위해 ReLU의 변형 함수들이 등장하기 시작했습니다. 변형 함수는 여러 개가 있지만 여기서는 Leaky ReLU에 대해서만 소개합니다. Leaky ReLU는 입력값이 음수일 경우에 0이 아니라 0.001과 같은 매우 작은 수를 반환
        - 입력값이 음수라도 기울기가 0이 되지 않으면 ReLU는 죽지 않습니다.
      - 소프트맥스 함수
        - 소프트맥스 함수는 시그모이드 함수처럼 출력층의 뉴런에서 주로 사용되는데, 시그모이드 함수가 두 가지 선택지 중 하나를 고르는 이진 분류 (Binary Classification) 문제에 사용된다면 세 가지 이상의 (상호 배타적인) 선택지 중 하나를 고르는 다중 클래스 분류(MultiClass Classification) 문제에 주로 사용됩니다.
  - 행렬의 곱셈을 이용한 순전파(Forward Propagation)



- 딥러닝 학습 방법?

  - 순전파(Forward Propagation)

    - 활성화 함수, 은닉층의 수, 각 은닉층의 뉴런 수 등 딥 러닝 모델을 설계하고나면 입력값은 입력층, 은닉층을 지나면서 각 층에서의 가중치와 함께 연산되며 출력층으로 향합니다. 그리고 출력층에서 모든 연산을 마친 예측값이 나오게 됩니다. 이와 같이 입력층에서 출력층 방향으로 예측값의 연산이 진행되는 과정을 순전파라고 합니다.

  - 손실 함수(Loss Function)
  
    - 손실 함수는 실제값과 예측값의 차이를 수치화해주는 함수
    - 두 값의 차이. 즉, 오차가 클 수록 손실 함수의 값은 크고 오차가 작을 수록 손실 함수의 값은 작아집니다
    - 손실 함수의 값을 최소화하는 두 개의 매개변수인 가중치 W와 편향 b를 찾아가는 것이 딥 러닝의 학습 과정
      - 오차 제곱 평균 (Mean Squared Error, MSE)
      - 크로스 엔트로피 (Cross-Entropy)
  
  - 옵티마이저
  
    - 손실 함수의 값을 줄여나가면서 학습하는 방법은 어떤 옵티마이저를 사용
      - 배치 경사 하강법(Batch Gradient Descent)
      - 확률적 경사 하강법(SGD)
      - 미니 배치 경사 하강법(Mini - Batch Gradient Descent)
      - 모멘텀(Momentum)
      - 아다그라드(Adagrad)
      - 알 엠 에스 프롭 (RMSprop)
      - 아담(Adam)

  - 에포크 (Epochs) ? 배치 크기 (Batch size) ? 이터레이션(Iteration)

    - 기계는 실제값과 예측값의 오차로부터 옵티마이저를 통해서 가중치를 업데이트합니다. 머신 러닝에서는 이 과정을 **학습**이라고 합니다. 이를 현실의 학습에 비유하면 사람은 문제지의 문제를 풀고, 정답지의 정답을 보면서 채점을 하면서 부족했던 점을 깨달으며 머릿속의 지식이 업데이트되는 과정입니다.

      그런데 사람마다 동일한 문제지와 정답지를 주더라도 공부 방법은 사실 천차만별입니다. 어떤 사람은 문제지 하나를 다 풀고 나서 정답을 채점하는데 어떤 사람은 문제지의 문제를 10개 단위로 끊어서 공부합니다. 문제 10개를 풀고 채점하고 다시 다음 문제 10개를 풀고 채점하고 반복하는 방식으로 학습한다는 거죠. 또한 게으른 사람은 문제지를 3번 공부하는데, 성실한 사람은 문제지의 문제를 달달 외울만큼 문제지를 100번 공부합니다.

      기계도 똑같습니다. 같은 문제지와 정답지를 주더라도 공부 방법을 다르게 설정할 수 있습니다.

    - 에포크

      - 에포크란 인공 신경망에서 전체 데이터에 대해서 순전파와 역전파가 끝난 상태를 말합니다. 전체 데이터를 하나의 문제지에 비유한다면 문제지의 모든 문제를 끝까지 다 풀고, 정답지로 채점을 하여 문제지에 대한 공부를 한 번 끝낸 상태를 말합니다.

        만약 에포크가 50이라고 하면, 전체 데이터 단위로는 총 50번 학습합니다. 문제지에 비유하면 문제지를 50번 푼 셈입니다. 이 에포크 횟수가 지나치거나 너무 적으면 앞서 배운 과적합과 과소적합이 발생할 수 있습니다.

    - 배치 사이즈

      - 배치 크기는 몇 개의 데이터 단위로 매개변수를 업데이트 하는지를 말합니다. 현실에 비유하면 문제지에서 몇 개씩 문제를 풀고나서 정답지를 확인하느냐의 문제입니다. 사람은 문제를 풀고 정답을 보는 순간 부족했던 점을 깨달으며 지식이 업데이트 된다고 하였습니다. 기계 입장에서는 실제값과 예측값으로부터 오차를 계산하고 옵티마이저가 매개변수를 업데이트합니다. 여기서 중요한 포인트는 업데이트가 시작되는 시점이 정답지/실제값을 확인하는 시점이라는 겁니다.

        사람이 2,000 문제가 수록되어있는 문제지의 문제를 200개 단위로 풀고 채점한다고 하면 이때 배치 크기는 200입니다. 기계는 배치 크기가 200이면 200개의 샘플 단위로 가중치를 업데이트 합니다.
  
        여기서 주의할 점은 배치 크기와 배치의 수는 다른 개념이라는 점입니다. 전체 데이터가 2,000일때 배치 크기를 200으로 준다면 배치의 수는 10입니다. 이는 에포크에서 배치 크기를 나눠준 값(2,000/200 = 10)이기도 합니다. 이때 배치의 수를 이터레이션이라고 합니다.
  
    - 이터레이션
  
      - 이터레이션이란 한 번의 에포크를 끝내기 위해서 필요한 배치의 수를 말합니다. 또는 한 번의 에포크 내에서 이루어지는 매개변수의 업데이트 횟수이기도 합니다. 전체 데이터가 2,000일 때 배치 크기를 200으로 한다면 이터레이션의 수는 총 10개입니다. 이는 한 번의 에포크 당 매개변수 업데이트가 10번 이루어진다는 것을 의미합니다. SGD를 이 개념을 가지고 다시 설명하면, SGD는 배치 크기가 1이므로 모든 이터레이션마다 하나의 데이터를 선택하여 경사 하강법을 수행합니다.



- 역전파 ?
  - 순전파가 입력층에서 출력층으로 향한다면 역전파는 반대로 출력층에서 입력층 방향으로 계산하면서 가중치를 업데이트해갑니다. 출력층 바로 이전의 은닉층을 N층이라고 하였을 때, 출력층과 N층 사이의 가중치를 업데이트하는 단계를 역전파 1단계, 그리고 N층과 N층의 이전층 사이의 가중치를 업데이트 하는 단계를 역전파 2단계



- 기울기 소실 ? 폭주 ?
  - 기울기 소실
    - 깊은 인공 신경망을 학습하다보면 역전파 과정에서 입력층으로 갈 수록 기울기(Gradient)가 점차적으로 작아지는 현상이 발생할 수 있습니다. 입력층에 가까운 층들에서 가중치들이 업데이트가 제대로 되지 않으면 결국 최적의 모델을 찾을 수 없게 됩니다. 이를 **기울기 소실(Gradient Vanishing)**
  - 폭주
    - 점차 커지더니 가중치들이 비정상적으로 큰 값이 되면서 결국 발산되기도 합니다. 이를 **기울기 폭주(Gradient Exploding)**이라고 하며, 뒤에서 배울 순환 신경망(Recurrent Neural Network, RNN)에서 발생할 수 있습니다.
  - 기울기 소실 방지법
    - ReLU와 ReLU 변형
    - 그래디언트 클리핑 (Gradient Clipping)
      - 그래디언트 클리핑은 말 그대로 기울기 값을 자르는 것을 의미합니다. 기울기 폭주를 막기 위해 임계값을 넘지 않도록 값을 자릅니다. 다시 말해서 임계치만큼 크기를 감소시킵니다. 이는 RNN에서 유용합니다. RNN은 BPTT에서 시점을 역행하면서 기울기를 구하는데, 이때 기울기가 너무 커질 수 있기 때문입니다. 케라스에서는 다음과 같은 방법으로 그래디언트 클리핑을 수행
    - 가중치 초기화
      - 같은 모델을 훈련시키더라도 가중치가 초기에 어떤 값을 가졌느냐에 따라서 모델의 훈련 결과가 달라지기도 합니다. 다시 말해 가중치 초기화만 적절히 해줘도 기울기 소실 문제과 같은 문제를 완화
        - 세이비어 초기화(Xavier Initialization)
        - He 초기화
    - 배치 정규화
      - 배치 정규화는 인공 신경망의 각 층에 들어가는 입력을 평균과 분산으로 정규화하여 학습을 효율적으로 만듭니다
        - 내부 공변량 변화(internal Covariate Shift)
        - 배치 정규화(batch Normalization)
    - 층 정규화



